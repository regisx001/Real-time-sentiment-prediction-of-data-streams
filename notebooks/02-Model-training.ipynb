{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "182360fc",
   "metadata": {},
   "source": [
    "# Step A1: Data Loading & Validation\n",
    "\n",
    "“Am I training on what I think I’m training on?”\n",
    "\n",
    "We load the cleaned dataset, validate the columns, handle null/empty values, and inspect the label distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff249e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Shape: (1599999, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>text_length</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>111</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>89</td>\n",
       "      <td>i dived many times for the ball. managed to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>Negative</td>\n",
       "      <td>47</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>Negative</td>\n",
       "      <td>111</td>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>Negative</td>\n",
       "      <td>29</td>\n",
       "      <td>not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text sentiment_label  \\\n",
       "0       0  is upset that he can't update his Facebook by ...        Negative   \n",
       "1       0  @Kenichan I dived many times for the ball. Man...        Negative   \n",
       "2       0    my whole body feels itchy and like its on fire         Negative   \n",
       "3       0  @nationwideclass no, it's not behaving at all....        Negative   \n",
       "4       0                      @Kwesidei not the whole crew         Negative   \n",
       "\n",
       "   text_length                                       cleaned_text  \n",
       "0          111  is upset that he can't update his facebook by ...  \n",
       "1           89   i dived many times for the ball. managed to s...  \n",
       "2           47    my whole body feels itchy and like its on fire   \n",
       "3          111   no, it's not behaving at all. i'm mad. why am...  \n",
       "4           29                                not the whole crew   "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"../data/cleaned.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {data_path}\")\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b3da8",
   "metadata": {},
   "source": [
    "## Validate Columns\n",
    "\n",
    "Explicitly check that `cleaned_text` and `target` (label) columns exist. This avoids hidden assumptions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae25cea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Passed: 'cleaned_text' and 'target' columns exist.\n"
     ]
    }
   ],
   "source": [
    "required_cols = ['cleaned_text', 'target']\n",
    "missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"CRITICAL ERROR: Missing required columns: {missing_cols}. Please check the previous preprocessing step.\")\n",
    "\n",
    "print(\"Validation Passed: 'cleaned_text' and 'target' columns exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240bea87",
   "metadata": {},
   "source": [
    "## Null & Empty Checks\n",
    "\n",
    "This is important for TF-IDF, which breaks on empty vocabulary. We must ensure streaming inference never receives empty input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a23e3ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rows: 1599999\n",
      "Dropped rows (null/empty): 2815\n",
      "Remaining rows: 1597184\n"
     ]
    }
   ],
   "source": [
    "# 1. Drop rows where cleaned_text is null\n",
    "initial_count = len(df)\n",
    "df = df.dropna(subset=['cleaned_text', 'target'])\n",
    "\n",
    "# 2. Drop rows where cleaned_text is empty string (after conversion to string to be safe)\n",
    "df = df[df['cleaned_text'].astype(str).str.strip() != \"\"]\n",
    "\n",
    "cleaned_count = len(df)\n",
    "dropped_count = initial_count - cleaned_count\n",
    "\n",
    "print(f\"Initial rows: {initial_count}\")\n",
    "print(f\"Dropped rows (null/empty): {dropped_count}\")\n",
    "print(f\"Remaining rows: {cleaned_count}\")\n",
    "\n",
    "if cleaned_count == 0:\n",
    "    raise ValueError(\"CRITICAL: Dataset is empty after cleaning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b70a6",
   "metadata": {},
   "source": [
    "## Label Sanity Check\n",
    "\n",
    "Understand binary vs multiclass and class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a00c8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: [0 4]\n",
      "\n",
      "Label Distribution:\n",
      "target\n",
      "4    798688\n",
      "0    798496\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Observation: Binary classification problem.\n"
     ]
    }
   ],
   "source": [
    "# Unique labels\n",
    "unique_labels = df['target'].unique()\n",
    "print(f\"Unique labels: {unique_labels}\")\n",
    "\n",
    "# Count occurrences\n",
    "label_counts = df['target'].value_counts()\n",
    "print(\"\\nLabel Distribution:\")\n",
    "print(label_counts)\n",
    "\n",
    "# Visual check of imbalance\n",
    "if len(unique_labels) > 2:\n",
    "    print(\"\\nObservation: Multi-class problem.\")\n",
    "else:\n",
    "    print(\"\\nObservation: Binary classification problem.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fca81",
   "metadata": {},
   "source": [
    "## Define Training Variables\n",
    "\n",
    "Prepare `X_text` and `y` for vectorization and splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73180333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training variables defined:\n",
      "X_text (Series): (1597184,)\n",
      "y (Series): (1597184,)\n",
      "\n",
      "Sample X_text:\n",
      "0    is upset that he can't update his facebook by ...\n",
      "1     i dived many times for the ball. managed to s...\n",
      "2      my whole body feels itchy and like its on fire \n",
      "Name: cleaned_text, dtype: object\n",
      "\n",
      "Sample y:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_text = df['cleaned_text']\n",
    "y = df['target']\n",
    "\n",
    "print(\"Training variables defined:\")\n",
    "print(f\"X_text (Series): {X_text.shape}\")\n",
    "print(f\"y (Series): {y.shape}\")\n",
    "\n",
    "# Peek at the data\n",
    "print(\"\\nSample X_text:\")\n",
    "print(X_text.head(3))\n",
    "print(\"\\nSample y:\")\n",
    "print(y.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec3515",
   "metadata": {},
   "source": [
    "# Step A2: Feature Extraction with TF-IDF\n",
    "\n",
    "\"How do we turn cleaned text into numbers that a model can learn from?\"\n",
    "\n",
    "We use TF-IDF (Term Frequency-Inverse Document Frequency) to convert text into numerical vectors. This approach gives higher weight to informative words and lower weight to common, less useful words.\n",
    "\n",
    "### Configuration\n",
    "- `max_features=5000`: Keeps the model small and inference fast.\n",
    "- `ngram_range=(1, 2)`: Captures single words and short phrases (e.g., \"not good\").\n",
    "- `min_df=5`: Ignores words that appear in fewer than 5 tweets to reduce noise.\n",
    "- `stop_words='english'`: Removes common English stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b34e6020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TF-IDF vectorization...\n",
      "Vectorization complete in 48.37 seconds.\n",
      "Shape: (1597184, 5000)\n",
      "Vocabulary size: 5000\n",
      "Vectorization complete in 48.37 seconds.\n",
      "Shape: (1597184, 5000)\n",
      "Vocabulary size: 5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "\n",
    "print(\"Starting TF-IDF vectorization...\")\n",
    "start_time = time.time()\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_features = vectorizer.fit_transform(X_text)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Vectorization complete in {end_time - start_time:.2f} seconds.\")\n",
    "print(f\"Shape: {X_features.shape}\")\n",
    "print(f\"Vocabulary size: {len(vectorizer.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a296af",
   "metadata": {},
   "source": [
    "# Step A3: Train & Evaluate Model (Logistic Regression)\n",
    "\n",
    "\"Can the model learn useful patterns from TF-IDF features?\"\n",
    "\n",
    "We choose **Logistic Regression** because it is:\n",
    "- **Fast** to train and predict (crucial for real-time streaming).\n",
    "- **Interpretable** (we can see which words drive sentiment).\n",
    "- **Strong Baseline** for text classification tasks.\n",
    "\n",
    "We will split the data (80/20), train the model, and evaluate it using standard classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "721b4962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data (80/20)...\n",
      "Train size: 1277747, Test size: 319437\n",
      "Training Logistic Regression...\n",
      "Train size: 1277747, Test size: 319437\n",
      "Training Logistic Regression...\n",
      "Training complete.\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Splitting data (80/20)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_features, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")\n",
    "\n",
    "print(\"Training Logistic Regression...\")\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a748b1f",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "We evaluate the model on the held-out test set using Accuracy, Precision, Recall, and F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dff4fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7692\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76    159699\n",
      "           4       0.75      0.80      0.78    159738\n",
      "\n",
      "    accuracy                           0.77    319437\n",
      "   macro avg       0.77      0.77      0.77    319437\n",
      "weighted avg       0.77      0.77      0.77    319437\n",
      "\n",
      "Metrics saved to ../ml/metrics.txt\n",
      "\n",
      "Top 10 Words Driving POSITIVE Sentiment:\n",
      "['proud', 'pleasure', 'blessed', 'smile', 'thanks', 'thank', 'welcome', 'congratulations', 'smiling', 'wish luck']\n",
      "\n",
      "Top 10 Words Driving NEGATIVE Sentiment:\n",
      "['sad', 'bummed', 'sadly', 'gutted', 'poor', 'sick', 'unfortunately', 'missing', 'sucks', 'disappointed']\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "with open(\"../ml/metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(report)\n",
    "print(\"Metrics saved to ../ml/metrics.txt\")\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefficients = log_reg.coef_[0]\n",
    "\n",
    "if len(log_reg.classes_) == 2:\n",
    "    top_positive_indices = np.argsort(coefficients)[-10:]\n",
    "    top_negative_indices = np.argsort(coefficients)[:10]\n",
    "\n",
    "    print(\"\\nTop 10 Words Driving POSITIVE Sentiment:\")\n",
    "    print([feature_names[i] for i in top_positive_indices])\n",
    "\n",
    "    print(\"\\nTop 10 Words Driving NEGATIVE Sentiment:\")\n",
    "    print([feature_names[i] for i in top_negative_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7d4d02",
   "metadata": {},
   "source": [
    "# Step A4: Persist the Trained ML Pipeline\n",
    "\n",
    "\"How can Spark later load and use the exact same model that was trained offline?\"\n",
    "\n",
    "We must save the **entire inference pipeline**, not just the classifier. This includes:\n",
    "1.  **TF-IDF Vectorizer**: To transform raw text into the exact same numerical features (same vocabulary, same index).\n",
    "2.  **Logistic Regression Classifier**: To predict sentiment from those features.\n",
    "\n",
    "We will bundle these into a single dictionary and serialize it to `sentiment_model.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b37d6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pipeline to ../ml/sentiment_model.pkl...\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "model_pipeline = {\n",
    "    \"vectorizer\": vectorizer,\n",
    "    \"classifier\": log_reg,\n",
    "    \"target_names\": [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "}\n",
    "\n",
    "model_dir = \"../ml\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_path = os.path.join(model_dir, \"sentiment_model.pkl\")\n",
    "\n",
    "print(f\"Saving pipeline to {model_path}...\")\n",
    "joblib.dump(model_pipeline, model_path)\n",
    "\n",
    "print(\"Model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
